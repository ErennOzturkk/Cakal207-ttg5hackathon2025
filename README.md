Etiket:#ttg5hackathon2025

# GeliÅŸmiÅŸ GÃ¶z Pedleri Kalite Kontrol Sistemi

![Eye Pad Quality Control Demo](https://via.placeholder.com/600x400?text=Proje+GÃ¶rseli+Eklenecek) 
*(Buraya projenizden bir Ã¶rnek gÃ¶rsel veya GIF ekleyebilirsiniz, Ã¶rn. modelin algÄ±lama yaptÄ±ÄŸÄ± bir gÃ¶rsel)*

## ğŸš€ Proje Genel BakÄ±ÅŸÄ±

Bu proje, yÃ¼ksek hassasiyetli Ultralytics YOLOv8 nesne algÄ±lama modelini kullanarak **gÃ¶z pedlerinin Ã¼retim hattÄ±ndaki kalite kusurlarÄ±nÄ± otomatik olarak tespit etmek** amacÄ±yla geliÅŸtirilmiÅŸtir. AmacÄ±mÄ±z, manuel denetimdeki insan hatalarÄ±nÄ± en aza indirerek ve kusur tespit sÃ¼reÃ§lerini otomatikleÅŸtirerek Ã¼retim verimliliÄŸini artÄ±rmaktÄ±r.

Hackathon sÃ¼recinde tasarlanan ve geliÅŸtirilen bu sistem, yapay zeka ve bilgisayar gÃ¶rÃ¼ÅŸÃ¼ alanÄ±ndaki bilgi birikimimizin bir Ã¼rÃ¼nÃ¼dÃ¼r.

## âœ¨ Temel Ã–zellikler

* **YOLOv8 Destekli Hassas AlgÄ±lama:** SektÃ¶r standardÄ± YOLOv8 mimarisi ile gÃ¼Ã§lÃ¼ ve gerÃ§ek zamanlÄ± kusur tespiti.
* **Ã–zelleÅŸtirilmiÅŸ Kusur SÄ±nÄ±flarÄ±:** GÃ¶z pedlerine Ã¶zgÃ¼ aÅŸaÄŸÄ±daki kritik kusur tiplerini baÅŸarÄ±yla algÄ±lar:
    * `saglam_ped` (SaÄŸlam ped)
    * `renk_degisimi` (Renk deÄŸiÅŸimi)
    * `leke` (Leke)
    * `yapi_bozulmasi` (YapÄ± bozulmasÄ±)
    * `kesim_hatasi` (Kesim hatasÄ±)
* **Ã‡oklu Platform UyumluluÄŸu:** EÄŸitilmiÅŸ model, farklÄ± daÄŸÄ±tÄ±m (deployment) ortamlarÄ± iÃ§in optimize edilmiÅŸ formatlara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lebilir:
    * **ONNX (.onnx):** Ã‡eÅŸitli programlama dilleri ve runtime'lar (C++, Java, .NET, Rust vb.) ile geniÅŸ uyumluluk.
    * **TensorFlow Lite (TFLite - .tflite):** Android cihazlar ve gÃ¶mÃ¼lÃ¼ sistemler iÃ§in optimize edilmiÅŸ, hafif ve hÄ±zlÄ± Ã§Ä±karÄ±m (FP32, FP16 ve INT8 nicemleme seÃ§enekleriyle).
* **Ã–zel Veri Seti:** GerÃ§ek dÃ¼nya Ã¼retim koÅŸullarÄ±nÄ± yansÄ±tan, Ã¶zenle etiketlenmiÅŸ Ã¶zel bir gÃ¶z pedleri veri seti Ã¼zerinde eÄŸitim.

## ğŸ“ Depo YapÄ±sÄ±

Proje dosyalarÄ± aÅŸaÄŸÄ±daki temel yapÄ±ya sahiptir:

.
â”œâ”€â”€ eye_pad_quality_control/
â”‚   â”œâ”€â”€ yolov8n_custom_dataset/
â”‚   â”‚   â”œâ”€â”€ images/  # EÄŸitim ve doÄŸrulama gÃ¶rselleri
â”‚   â”‚   â”œâ”€â”€ labels/  # YOLO formatÄ±ndaki etiketler
â”‚   â”‚   â””â”€â”€ weights/ # EÄŸitilmiÅŸ model aÄŸÄ±rlÄ±klarÄ± (best.pt, best.onnx, best.tflite)
â”‚   â””â”€â”€ data.yaml    # Veri seti yapÄ±landÄ±rma dosyasÄ±
â”œâ”€â”€ train.py         # Model eÄŸitim betiÄŸi (veya Jupyter Notebook iÃ§inde)
â”œâ”€â”€ inference.py     # Model ile tahmin yapma betiÄŸi (Ã–rnek)
â”œâ”€â”€ convert_models.py # Model dÃ¶nÃ¼ÅŸÃ¼m betiÄŸi (ONNX, TFLite)
â”œâ”€â”€ README.md        # Bu dosya
â””â”€â”€ requirements.txt # Proje baÄŸÄ±mlÄ±lÄ±klarÄ±


## ğŸ› ï¸ Kurulum

Projeyi yerel makinenizde Ã§alÄ±ÅŸtÄ±rabilmek iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± takip edin:

1.  **Depoyu KlonlayÄ±n:**
    ```bash
    git clone [https://github.com/ErennOzturkk/Cakal207-ttg5hackathon2025.git](https://github.com/ErennOzturkk/Cakal207-ttg5hackathon2025.git)
    cd Cakal207-ttg5hackathon2025
    ```

2.  **Sanal Ortam OluÅŸturun (Åiddetle Tavsiye Edilir):**
    BaÄŸÄ±mlÄ±lÄ±k Ã§akÄ±ÅŸmalarÄ±nÄ± Ã¶nlemek iÃ§in yeni bir Python sanal ortamÄ± oluÅŸturun ve etkinleÅŸtirin.

    ```bash
    python -m venv yolov8_env
    .\yolov8_env\Scripts\activate # Windows iÃ§in
    # source yolov8_env/bin/activate # Linux/macOS iÃ§in
    ```

3.  **BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin:**
    `requirements.txt` dosyanÄ±z varsa, oradan yÃ¼kleyebilirsiniz. Yoksa, aÅŸaÄŸÄ±daki komutlarÄ± kullanarak gerekli tÃ¼m kÃ¼tÃ¼phaneleri belirtilen uyumlu sÃ¼rÃ¼mlerle yÃ¼kleyin:

    ```bash
    pip install --upgrade pip
    pip install ultralytics==8.3.141
    pip install protobuf==3.20.1
    pip install tensorflow==2.10.0 # Python 3.9 ile uyumlu CPU versiyonu
    pip install onnx==1.17.0 onnxruntime onnxslim
    pip install tf_keras
    pip install sng4onnx>=1.0.1
    pip install onnx_graphsurgeon>=0.3.26
    pip install ai-edge-litert>=1.2.0
    pip install onnx2tf>=1.26.3
    ```
    *Not: TensorFlow sÃ¼rÃ¼mÃ¼ Python sÃ¼rÃ¼mÃ¼nÃ¼ze ve CUDA/GPU durumunuza gÃ¶re deÄŸiÅŸebilir. EÄŸer `tensorflow==2.10.0` ile sorun yaÅŸarsanÄ±z, sadece `pip install tensorflow` deneyip sonrasÄ±nda `protobuf`'u tekrar `3.20.1`'e dÃ¼ÅŸÃ¼rmeyi deneyebilirsiniz.*

## ğŸš€ KullanÄ±m

### Veri Seti HazÄ±rlÄ±ÄŸÄ±

Veri setinizi `eye_pad_quality_control/yolov8n_custom_dataset` dizini altÄ±nda aÅŸaÄŸÄ±daki yapÄ±ya uygun ÅŸekilde dÃ¼zenleyin:

eye_pad_quality_control/yolov8n_custom_dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â””â”€â”€ labels/
â”œâ”€â”€ train/
â””â”€â”€ val/
â””â”€â”€ test/


`data.yaml` dosyanÄ±z (Ã¶rnek: `eye_pad_quality_control/data.yaml`), veri setinizin yollarÄ±nÄ± ve sÄ±nÄ±f isimlerini tanÄ±mlamalÄ±dÄ±r:

```yaml
# data.yaml iÃ§eriÄŸi
path: ../eye_pad_quality_control/yolov8n_custom_dataset/  # Veri setinizin ana yolu
train: images/train # EÄŸitim gÃ¶rselleri
val: images/val     # DoÄŸrulama gÃ¶rselleri
test: images/test   # Test gÃ¶rselleri (opsiyonel)

names:
  0: saglam_ped
  1: renk_degisimi
  2: leke
  3: yapi_bozulmasi
  4: kesim_hatasi
Modeli EÄŸitme
EÄŸitim sÃ¼recini baÅŸlatmak iÃ§in train.py dosyasÄ±nÄ± (veya Jupyter Notebook iÃ§inde ilgili hÃ¼creleri) kullanÄ±n:

Python

# train.py veya Jupyter Notebook hÃ¼cresi
from ultralytics import YOLO

# Modeli baÅŸlatÄ±n (Ã¶nceden eÄŸitilmiÅŸ 'n' nano modeli ile baÅŸlayabiliriz)
model = YOLO('yolov8n.pt') 

# Modeli Ã¶zel veri setinizde eÄŸitin
results = model.train(data='eye_pad_quality_control/data.yaml', epochs=50, imgsz=640, device='cpu')
# GPU kullanmak iÃ§in 'device=0' (veya uygun GPU ID) ayarlayabilirsiniz.
Modeli DeÄŸerlendirme
EÄŸitilen modelin performansÄ±nÄ± doÄŸrulama seti Ã¼zerinde deÄŸerlendirin:

Python

# inference.py veya Jupyter Notebook hÃ¼cresi
from ultralytics import YOLO

# EÄŸitilmiÅŸ modeli yÃ¼kle
model = YOLO('eye_pad_quality_control/yolov8n_custom_dataset/weights/best.pt') 

# Modelin performansÄ±nÄ± deÄŸerlendir
metrics = model.val()

print(f"Mean Average Precision (mAP@0.50-0.95): {metrics.results_dict['metrics/mAP50-95(B)']}")
print(f"Mean Average Precision (mAP@0.50): {metrics.results_dict['metrics/mAP50(B)']}")
Ã‡Ä±karÄ±m (Prediction) Yapma
Yeni gÃ¶rÃ¼ntÃ¼ler Ã¼zerinde tahminler yapmak iÃ§in:

Python

# inference.py veya Jupyter Notebook hÃ¼cresi
from ultralytics import YOLO

# EÄŸitilmiÅŸ modeli yÃ¼kle
model = YOLO('eye_pad_quality_control/yolov8n_custom_dataset/weights/best.pt') 

# Tek bir gÃ¶rÃ¼ntÃ¼de tahmin yap
results = model('path/to/your/image.jpg', conf=0.25, iou=0.7) # GÃ¼ven eÅŸiÄŸi 0.25, IOU eÅŸiÄŸi 0.7

# SonuÃ§larÄ± gÃ¶rselleÅŸtir veya kaydet
for r in results:
    im_bgr = r.plot()  # Ã‡Ä±karÄ±m kutularÄ±nÄ± ve etiketleri gÃ¶rÃ¼ntÃ¼ye Ã§iz
    # cv2.imshow('Prediction', im_bgr) # EÄŸer OpenCV kuruluysa ve gÃ¶rselleÅŸtirmek istersen
    # cv2.imwrite('predicted_image.jpg', im_bgr) # Kaydetmek iÃ§in
Model DÃ¶nÃ¼ÅŸÃ¼mleri
EÄŸitilmiÅŸ modelinizi farklÄ± daÄŸÄ±tÄ±m platformlarÄ± iÃ§in optimize edilmiÅŸ formatlara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n.

1. ONNX FormatÄ±na DÃ¶nÃ¼ÅŸtÃ¼rme
Python

# convert_models.py veya Jupyter Notebook hÃ¼cresi
from ultralytics import YOLO

model_path = 'eye_pad_quality_control/yolov8n_custom_dataset/weights/best.pt'
model = YOLO(model_path)

print("Model ONNX formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
results_onnx = model.export(format='onnx', imgsz=640, device='cpu', simplify=True)
print(f"ONNX modeli baÅŸarÄ±yla kaydedildi: {results_onnx}")
2. TensorFlow Lite (TFLite) FormatÄ±na DÃ¶nÃ¼ÅŸtÃ¼rme
Bu sÃ¼reÃ§, PyTorch modelini Ã¶nce ONNX'e, oradan TensorFlow SavedModel'a ve son olarak TFLite'a dÃ¶nÃ¼ÅŸtÃ¼rme adÄ±mlarÄ±nÄ± iÃ§erir.

Python

# convert_models.py veya Jupyter Notebook hÃ¼cresi
import onnx2tf
import tensorflow as tf
import os
from ultralytics import YOLO
import numpy as np

model_path = 'eye_pad_quality_control/yolov8n_custom_dataset/weights/best.pt'
model = YOLO(model_path)

# 1. AdÄ±m: PyTorch (.pt) modelini ONNX'e dÃ¶nÃ¼ÅŸtÃ¼r (eÄŸer henÃ¼z yapmadÄ±ysanÄ±z)
print("ONNX model oluÅŸturuluyor...")
# Bu kÄ±sÄ±m zaten baÅŸarÄ±yla yapÄ±lmÄ±ÅŸ olmalÄ±, eÄŸer yoksa tekrar Ã§alÄ±ÅŸtÄ±rÄ±n
model.export(format='onnx', imgsz=640, device='cpu', simplify=True)
onnx_model_path = 'eye_pad_quality_control/yolov8n_custom_dataset/weights/best.onnx'
print(f"ONNX modeli kaydedildi: {onnx_model_path}")

# 2. AdÄ±m: ONNX modelini TensorFlow SavedModel'a dÃ¶nÃ¼ÅŸtÃ¼r
output_saved_model_dir = 'eye_pad_quality_control/yolov8n_custom_dataset/weights/saved_model_tf'
print(f"\nONNX modelini TensorFlow SavedModel'a dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor: {output_saved_model_dir}")
onnx2tf.convert(
    input_onnx_file_path=onnx_model_path,
    output_folder_path=output_saved_model_dir,
    non_verbose=True
)
print("TensorFlow SavedModel baÅŸarÄ±yla oluÅŸturuldu.")

# 3. AdÄ±m: TensorFlow SavedModel'Ä± TFLite'a dÃ¶nÃ¼ÅŸtÃ¼r
# Ã‡Ä±kÄ±ÅŸ TFLite dosya yollarÄ±
output_tflite_path_fp32 = os.path.join(output_saved_model_dir, 'best_fp32.tflite')
output_tflite_path_fp16 = os.path.join(output_saved_model_dir, 'best_fp16.tflite')
output_tflite_path_int8 = os.path.join(output_saved_model_dir, 'best_int8.tflite')

# FP32 TFLite DÃ¶nÃ¼ÅŸÃ¼mÃ¼
print("\nTensorFlow SavedModel'dan FP32 TFLite'a dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
converter_fp32 = tf.lite.TFLiteConverter.from_saved_model(output_saved_model_dir)
tflite_model_fp32 = converter_fp32.convert()
with open(output_tflite_path_fp32, 'wb') as f:
    f.write(tflite_model_fp32)
print(f"FP32 TFLite modeli baÅŸarÄ±yla kaydedildi: {output_tflite_path_fp32}")

# FP16 TFLite DÃ¶nÃ¼ÅŸÃ¼mÃ¼ (Opsiyonel)
print("\nTensorFlow SavedModel'dan FP16 TFLite'a dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
converter_fp16 = tf.lite.TFLiteConverter.from_saved_model(output_saved_model_dir)
converter_fp16.optimizations = [tf.lite.Optimize.DEFAULT]
converter_fp16.target_spec.supported_types = [tf.float16]
tflite_model_fp16 = converter_fp16.convert()
with open(output_tflite_path_fp16, 'wb') as f:
    f.write(tflite_model_fp16)
print(f"FP16 TFLite modeli baÅŸarÄ±yla kaydedildi: {output_tflite_path_fp16}")
 INT8 TFLite DÃ¶nÃ¼ÅŸÃ¼mÃ¼ (Opsiyonel - Temsili Veri KÃ¼mesi Gerektirir)
print("\nTensorFlow SavedModel'dan INT8 TFLite'a dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
converter_int8 = tf.lite.TFLiteConverter.from_saved_model(output_saved_model_dir)
converter_int8.optimizations = [tf.lite.Optimize.DEFAULT]
converter_int8.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter_int8.inference_input_type = tf.uint8 # GiriÅŸ tipi uint8 olarak ayarlanabilir
converter_int8.inference_output_type = tf.uint8 # Ã‡Ä±kÄ±ÅŸ tipi uint8 olarak ayarlanabilir

import numpy as np
def representative_dataset_gen():
    # GerÃ§ek veri setinizden (Ã¶rn. eÄŸitim veya doÄŸrulama setinden)
    # 20-100 adet normalize edilmiÅŸ gÃ¶rÃ¼ntÃ¼ Ã¶rneÄŸi saÄŸlamalÄ±sÄ±nÄ±z.
    # Her gÃ¶rÃ¼ntÃ¼ (1, 640, 640, 3) boyutunda np.float32 tipinde olmalÄ±.
    # Ã–rneÄŸin:
    # for img_path in your_train_image_paths[:20]:
    #     img = cv2.imread(img_path)
    #     img = cv2.resize(img, (640, 640))
    #     img = img / 255.0 # Normalize to [0, 1]
    #     yield [np.expand_dims(img, axis=0).astype(np.float32)]
    
    # Åimdilik rastgele veri ile Ã¶rnek veriyoruz:
    for _ in range(20): 
        data = np.random.rand(1, 640, 640, 3).astype(np.float32)
        yield [data]

converter_int8.representative_dataset = representative_dataset_gen
tflite_model_int8 = converter_int8.convert()
with open(output_tflite_path_int8, 'wb') as f:
    f.write(tflite_model_int8)
print(f"INT8 TFLite modeli baÅŸarÄ±yla kaydedildi: {output_tflite_path_int8}")

ğŸ¤ KatkÄ±da Bulunma
Projeye katkÄ±da bulunmak isterseniz aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyebilirsiniz:

Bu depoyu (repository) Ã§atallayÄ±n (fork).
Yeni bir Ã¶zellik dalÄ± (feature branch) oluÅŸturun: git checkout -b ozellik/yeni-ozellik
DeÄŸiÅŸikliklerinizi yapÄ±n ve commit edin: git commit -m 'Yeni Ã¶zellik: AÃ§Ä±klama'
DalÄ± push edin: git push origin ozellik/yeni-ozellik
Bir Pull Request (Ã‡ekme Ä°steÄŸi) oluÅŸturun.
